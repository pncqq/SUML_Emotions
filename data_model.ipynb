{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T16:52:47.557070Z",
     "start_time": "2024-11-12T16:52:42.872430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Przygotowanie danych\n",
    "splits_1 = {'train': 'train.csv', 'validation': 'dev.csv', 'test': 'test.csv'}\n",
    "df_1 = pd.read_csv(\"hf://datasets/Adapting/empathetic_dialogues_v2/\" + splits_1[\"train\"])\n",
    "\n",
    "splits_2 = {'train': 'train.jsonl', 'validation': 'validation.jsonl', 'test': 'test.jsonl'}\n",
    "df_2 = pd.read_json(\"hf://datasets/SetFit/emotion/\" + splits_2[\"train\"], lines=True)\n",
    "\n",
    "df_1.drop(columns=['id', 'chat_history', 'sys_response', 'question or not', 'behavior'], inplace=True)\n",
    "df_2.drop(columns=['label'], inplace=True)\n",
    "\n",
    "df_1.rename(columns={'situation': 'text'}, inplace=True)\n",
    "df_2.rename(columns={'label_text': 'emotion'}, inplace=True)\n",
    "\n",
    "combined_df = pd.concat([df_1, df_2])\n",
    "combined_df"
   ],
   "id": "9abaa39f4bc89e84",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                    text    emotion\n",
       "0      I have always been a big fan of childrens plac...   faithful\n",
       "1                                          I am piss-off      angry\n",
       "2      I am feeling happy I can afford what I need fo...     joyful\n",
       "3      I saw my friend projectile vomit on the roller...  disgusted\n",
       "4      I was very happy when I got to see my aunt at ...   grateful\n",
       "...                                                  ...        ...\n",
       "15995  i just had a very brief time in the beanbag an...    sadness\n",
       "15996  i am now turning and i feel pathetic that i am...    sadness\n",
       "15997                     i feel strong and good overall        joy\n",
       "15998  i feel like this was such a rude comment and i...      anger\n",
       "15999  i know a lot but i feel so stupid because i ca...    sadness\n",
       "\n",
       "[56245 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have always been a big fan of childrens plac...</td>\n",
       "      <td>faithful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am piss-off</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am feeling happy I can afford what I need fo...</td>\n",
       "      <td>joyful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw my friend projectile vomit on the roller...</td>\n",
       "      <td>disgusted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was very happy when I got to see my aunt at ...</td>\n",
       "      <td>grateful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56245 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T16:52:47.599772Z",
     "start_time": "2024-11-12T16:52:47.589423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(\"Czy CUDA jest dostępna:\", torch.cuda.is_available())\n",
    "print(\"Nazwa GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Brak GPU\")\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')"
   ],
   "id": "5a47efd94487969d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czy CUDA jest dostępna: True\n",
      "Nazwa GPU: NVIDIA GeForce RTX 4070 Ti SUPER\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-12T18:07:03.559040Z",
     "start_time": "2024-11-12T16:52:47.696363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(combined_df, test_size=0.2, random_state=42)\n",
    "\n",
    "predictor = MultiModalPredictor(label='emotion')\n",
    "predictor.fit(train_df)\n",
    "\n",
    "performance = predictor.evaluate(test_df)\n",
    "print(\"Wyniki modelu:\\n\", performance)\n",
    "\n",
    "performance"
   ],
   "id": "d86e46192dc23b99",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20241112_165247\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.8.20\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.26100\n",
      "CPU Count:          12\n",
      "Pytorch Version:    2.4.1\n",
      "CUDA Version:       12.4\n",
      "Memory Avail:       17.25 GB / 31.62 GB (54.6%)\n",
      "Disk Space Avail:   344.71 GB / 797.50 GB (43.2%)\n",
      "===================================================\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 38) unique label values:  ['terrified', 'sentimental', 'trusting', 'disgusted', 'annoyed', 'sadness', 'anger', 'love', 'content', 'joy']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "\n",
      "AutoMM starts to create your model. ✨✨✨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir E:\\Projekty\\DataSpellProjects\\SUML_Emotions\\AutogluonModels\\ag-20241112_165247\n",
      "    ```\n",
      "\n",
      "Seed set to 0\n",
      "D:\\Programy\\Anaconda3\\envs\\autogluon\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "D:\\Programy\\Anaconda3\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:54: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                         | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | model             | HFAutoModelForTextPrediction | 108 M \n",
      "1 | validation_metric | MulticlassAccuracy           | 0     \n",
      "2 | loss_func         | CrossEntropyLoss             | 0     \n",
      "-------------------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "435.683   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8df74dfa24564dbeb7a498a05e2cab48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a79672de32d4c31839e7695c4f99ae2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf8b62ccd429412996c73bb815c93d1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 166: 'val_accuracy' reached 0.33680 (best 0.33680), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=0-step=166.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3d4533135bb46cea67677ffc2991303"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 332: 'val_accuracy' reached 0.61800 (best 0.61800), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=0-step=332.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79656becd21e4c28851ce3f02a89a71a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 498: 'val_accuracy' reached 0.67840 (best 0.67840), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=1-step=498.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71a8b453689a44aeb2b510f225115612"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 664: 'val_accuracy' reached 0.70040 (best 0.70040), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=1-step=664.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "873fca52ef6042d6ab7fa906d088cd07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 830: 'val_accuracy' reached 0.71840 (best 0.71840), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=2-step=830.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d49a7f31be3f4009b8b9f3c05f652d7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 996: 'val_accuracy' reached 0.75600 (best 0.75600), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=2-step=996.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31b7f2e210f648928ddb3184ea6478fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1162: 'val_accuracy' reached 0.77240 (best 0.77240), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=3-step=1162.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "64c699a2e48b4435bb68d41e26875e72"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 1328: 'val_accuracy' reached 0.79280 (best 0.79280), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=3-step=1328.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11f29872df9d4fc0b512f36a367b2ee1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1494: 'val_accuracy' reached 0.80280 (best 0.80280), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=4-step=1494.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2d9dd95a0604d0180cecae62ebfcce7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1660: 'val_accuracy' reached 0.81440 (best 0.81440), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=4-step=1660.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b7cd75d27194b7586470be5758588f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1826: 'val_accuracy' reached 0.82880 (best 0.82880), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=5-step=1826.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06251b472d144cd183bfc53c37bc5ce9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1992: 'val_accuracy' reached 0.84720 (best 0.84720), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=5-step=1992.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa78b006e478437f8272a52b2925520f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 2158: 'val_accuracy' reached 0.84640 (best 0.84720), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=6-step=2158.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f2c85f889454f3c831a4a7eb75ab409"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 2324: 'val_accuracy' reached 0.85560 (best 0.85560), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=6-step=2324.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0edec4eee16243ffae00a4ece16015dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2490: 'val_accuracy' reached 0.87640 (best 0.87640), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=7-step=2490.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2da5589a1b484c618c6ae460b9a68730"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 2656: 'val_accuracy' reached 0.87920 (best 0.87920), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=7-step=2656.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3dda3c96b36742faa1fce2982fedf648"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2822: 'val_accuracy' reached 0.87640 (best 0.87920), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=8-step=2822.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65f83f5f5a384088a187c53098f05fa7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2988: 'val_accuracy' reached 0.88880 (best 0.88880), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=8-step=2988.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5fed1312e474f20a120c9fec085f1e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 3154: 'val_accuracy' reached 0.88320 (best 0.88880), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=9-step=3154.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33bbb94bf64049eb956f15a78e551da7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 3320: 'val_accuracy' reached 0.88960 (best 0.88960), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=9-step=3320.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab44da7ed52e439990c19cdd61c493d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 3486: 'val_accuracy' reached 0.89080 (best 0.89080), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=10-step=3486.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2f83f6bcf134191adea9f165fc00944"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 3652: 'val_accuracy' reached 0.89440 (best 0.89440), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=10-step=3652.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a30f7eeb755d46ceac528da1fa418100"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 3818: 'val_accuracy' reached 0.89280 (best 0.89440), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=11-step=3818.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b609b8c3c44448a8bfd119981533f921"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 3984: 'val_accuracy' reached 0.90000 (best 0.90000), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=11-step=3984.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c61fc3446fe44e6a6c6b616dbebe779"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 4150: 'val_accuracy' reached 0.90120 (best 0.90120), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=12-step=4150.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f165acb46979480db32f3269101c7408"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 4316: 'val_accuracy' reached 0.89760 (best 0.90120), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=12-step=4316.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5637ee884365409199fb8e2206781965"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 4482: 'val_accuracy' reached 0.90320 (best 0.90320), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=13-step=4482.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c8c4d6605c14492a9d12e017c53fa55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 4648: 'val_accuracy' reached 0.90320 (best 0.90320), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=13-step=4648.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28132b5111524b149a66cfe0e7365b32"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 4814: 'val_accuracy' reached 0.90600 (best 0.90600), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=14-step=4814.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15f01f21b69642308ae796282ff8932e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 4980: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e8ca3e13e5d43759f31b55016d114f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 5146: 'val_accuracy' reached 0.90680 (best 0.90680), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=15-step=5146.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bd5e57a5c16e498392795c8322db3492"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 5312: 'val_accuracy' reached 0.90480 (best 0.90680), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=15-step=5312.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6f112869c5c44edb738ce9f46abe594"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 5478: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9cd69e96c0d49f5be06f9d4867f6621"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 5644: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a5131f8ec624f49bca9300a4d8238c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 5810: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7974079083614c5b90b79248bae67c2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 5976: 'val_accuracy' reached 0.90600 (best 0.90680), saving model to 'E:\\\\Projekty\\\\DataSpellProjects\\\\SUML_Emotions\\\\AutogluonModels\\\\ag-20241112_165247\\\\epoch=17-step=5976.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18c39e832a8d4289aaa40a384138cf13"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 6142: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eaf877c68c8c4f25b65dbc375f910e0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 6308: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f9f96b48ced4e60b70168d18453bcd6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 6474: 'val_accuracy' was not in top 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78b4efa899904026984e1164993fd007"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 6640: 'val_accuracy' was not in top 3\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n",
      "D:\\Programy\\Anaconda3\\envs\\autogluon\\lib\\site-packages\\autogluon\\multimodal\\learners\\base.py:2111: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "D:\\Programy\\Anaconda3\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:54: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98ac0bcdbfc34689b84d1c0c51e951e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programy\\Anaconda3\\envs\\autogluon\\lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(per_path, map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "D:\\Programy\\Anaconda3\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:54: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a0c92b95d80f4459ab322bd610b44578"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programy\\Anaconda3\\envs\\autogluon\\lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(per_path, map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "D:\\Programy\\Anaconda3\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:54: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e86ae2f0874447ebb66d3f45341bd210"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programy\\Anaconda3\\envs\\autogluon\\lib\\site-packages\\autogluon\\multimodal\\utils\\checkpoint.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(per_path, map_location=torch.device(\"cpu\"))[\"state_dict\"]\n",
      "AutoMM has created your model. 🎉🎉🎉\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"E:\\Projekty\\DataSpellProjects\\SUML_Emotions\\AutogluonModels\\ag-20241112_165247\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n",
      "D:\\Programy\\Anaconda3\\envs\\autogluon\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\amp.py:54: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad6e72c9bce74f5c98384418c8c5bd55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wyniki modelu:\n",
      " {'accuracy': 0.9076362343319406}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9076362343319406}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
